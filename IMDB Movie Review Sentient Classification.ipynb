{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implementation of Sentient Classifier\n",
    "Here we present our realization of LSTM neural network that is trained to distinguish negative IMDB reviews from positive ones.\n",
    "\n",
    "We will use Python together with Keras for LSTM implementation and it's IMDB dataset.\n",
    "The baseline will be: at least 80\\%$ of the final accuracy on the test data.\n",
    "\n",
    "Hovewer, we don't want to simply copy Jason Brownlee's solution, which he presented in [http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/]. Thus we will try to comment each line of code to show what is going on. We'll also try to explain why did we choose a particular parameter, so no magic constants will be involved.\n",
    "\n",
    "Now, first of all we need to import all vital modules:\n",
    "\n",
    "1. IMDB movie review dataset. It'll be our source of data.\n",
    "2. Sequential model which we will use to implement our LSTM.\n",
    "3. Dense layer for single output.\n",
    "4. LSTM layer.\n",
    "5. Embedding layer for shrinking the dimentions of the data.\n",
    "6. \"Sequence\" class for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's discuss its structure. IMDB dataset is a tuple of tuples, where each tuple represents a review, in which every word is replaced by its index in a vocabulary constructed from these reviews.\n",
    "We can access this vocabulary by using the method \"get_word_index\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocabulary = imdb.get_word_index()\n",
    "# Keep in mind that it's quite large\n",
    "# print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we need to load the dataset. IMDB class provides a convenient  function \"load_data\" that returns the dataset (x, y) split in half for training and testing.\n",
    "\n",
    "Also, this function gives us the ability to choose only the top N words. Following the Jason Brownlee we also pick only the first five thousants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "amount_of_first_top_words = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review representation sample: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "Class representation sample: 1\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=amount_of_first_top_words)\n",
    "print('Review representation sample: %s' % x_train[0])\n",
    "print('Class representation sample: %s' % y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We must mention that it's a standart way to represent a sentence by it's \"inverted\" frequency.\n",
    "\n",
    "Notice that some reviews are short and some are long, thus we need to either truncate or enlarge them with zeroes, since Keras accepts only the vectors of the same lenght. It can be done by the \"sequence\" module.\n",
    "\n",
    "Also we introduce another constant: the maximum length of the review. After looking at the length distribution, we decided to set this value to 600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_review_length = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_test  = sequence.pad_sequences(x_test, maxlen=max_review_length)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll start to prepare our model. In Keras a model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as little restrictions as possible. Combined modules form what is called a 'layer', and layers, in their turn, are grouped together to form a model. In other words, in Keras, a model can be throught as a way to organize layers. The simplest model is \"Sequential\", it just a linear stack of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There is a problem with our dataset. Unfortunately, each word in a review represented only by an integer, but supplying a word to Keras requires it to be a real vector.\n",
    "\n",
    "We can solve this problem by introducing vector embedding to our model as a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embedding_vector_length = 32\n",
    "model.add(Embedding(amount_of_first_top_words, embedding_vector_length, input_length=max_review_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that we created new constant \"embedding_vector_length\" which governs the dimensionality of the output vectors. We'll stick with Jason Brownlee's choice.\n",
    "\n",
    "Now it's time to add the LSTM to our model! This layer has only one parameter: the number of memrons (special neurons with memory). The author choose to set this parameter to 100, so we will follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.add(LSTM(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Last layer that we need to add is 'Dense' layer. It will act like a usual neuron with 'n' outputs, 'sigmoid' activation function and no bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, our model must be compiled, which means that we need to specify various parameters, such as 'loss function' or 'metrics'.\n",
    "We are okay with Jason Brownlee's choise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see the summary of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301.0\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice how big the total number of parameters is: 231,301! For such a simple model! No wonder why machine learning is so hard.\n",
    "\n",
    "Finally it is time to train our model by the \"fit\" method, which has many parameters, but we use only two: number of epoches and batch size. Keep in mind that it will take time to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, num_epoch=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can assess the accuracy of our trained model through the \"evaluate\" method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assess = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Evaluated accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see, our model achives 86,6% of accuracy and thus passes the requested baseline. This concludes our report on the first part of the assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
